{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Layer, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "import pdb\n",
    "# class Identity(Layer):\n",
    "#     def call(self, x, mask=None):\n",
    "#         return x\n",
    "\n",
    "def building_residual_block(input_shape, n_feature_maps, kernel_sizes=None, n_skip=2, is_subsample=False, subsample=None):\n",
    "    '''\n",
    "    [1] Building block of layers for residual learning.\n",
    "        Code based on https://github.com/ndronen/modeling/blob/master/modeling/residual.py\n",
    "        , but modification of (perhaps) incorrect relu(f)+x thing and it's for conv layer\n",
    "    [2] MaxPooling is used instead of strided convolution to make it easier \n",
    "        to set size(output of short-cut) == size(output of conv-layers).\n",
    "        If you want to remove MaxPooling,\n",
    "           i) change (border_mode in Convolution2D in shortcut), 'same'-->'valid'\n",
    "           ii) uncomment ZeroPadding2D in conv layers.\n",
    "               (Then the following Conv2D is not the first layer of this container anymore,\n",
    "                so you can remove the input_shape in the line 101, the line with comment #'OPTION' )\n",
    "    [3] It can be used for both cases whether it subsamples or not.\n",
    "    [4] In the short-cut connection, I used 1x1 convolution to increase #channel.\n",
    "        It occurs when is_expand_channels == True \n",
    "    input_shape = (None, num_channel, height, width) \n",
    "    n_feature_maps: number of feature maps. In ResidualNet it increases whenever image is downsampled.\n",
    "    kernel_sizes : list or tuple, (3,3) or [3,3] for example\n",
    "    n_skip       : number of layers to skip\n",
    "    is_subsample : If it is True, the layers subsamples by *subsample* to reduce the size.\n",
    "    subsample    : tuple, (2,2) or (1,2) for example. Used only if is_subsample==True\n",
    "    '''\n",
    "    # ***** VERBOSE_PART ***** \n",
    "    print ('   - New residual block with')\n",
    "    print ('      input shape:', input_shape)\n",
    "    print ('      kernel size:', kernel_sizes)\n",
    "    # is_expand_channels == True when num_channels increases.\n",
    "    #    E.g. the very first residual block (e.g. 1->64, 3->128, 128->256, ...)\n",
    "    is_expand_channels = not (input_shape[0] == n_feature_maps) \n",
    "    if is_expand_channels:\n",
    "        print ('      - Input channels: %d ---> num feature maps on out: %d' % (input_shape[0], n_feature_maps)  )\n",
    "    if is_subsample:\n",
    "        print ('      - with subsample:', subsample)\n",
    "    kernel_row, kernel_col = kernel_sizes\n",
    "    # set input\n",
    "    x = Input(shape=(input_shape))\n",
    "    # ***** SHORTCUT PATH *****\n",
    "    if is_subsample: # subsample (+ channel expansion if needed)\n",
    "        shortcut_y = Convolution2D(n_feature_maps, kernel_sizes[0], kernel_sizes[1], \n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='valid')(x)\n",
    "    else: # channel expansion only (e.g. the very first layer of the whole networks)\n",
    "        if is_expand_channels:\n",
    "            shortcut_y = Convolution2D(n_feature_maps, 1, 1, border_mode='same')(x)\n",
    "        else:\n",
    "            # if no subsample and no channel expension, there's nothing to add on the shortcut.\n",
    "            shortcut_y = x\n",
    "    # ***** CONVOLUTION_PATH ***** \n",
    "    conv_y = x\n",
    "    for i in range(n_skip):\n",
    "        #**conv_y = BatchNormalization(axis=1, mode=2)(conv_y)        \n",
    "        conv_y = Activation('relu')(conv_y)\n",
    "        if i==0 and is_subsample: # [Subsample at layer 0 if needed]\n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row, kernel_col,\n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='valid')(conv_y)  \n",
    "        else:        \n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row, kernel_col, border_mode='same')(conv_y)\n",
    "    # output\n",
    "    y = merge([shortcut_y, conv_y], mode='sum')\n",
    "    block = Model(input=x, output=y)\n",
    "    print ('        -- model was built.')\n",
    "    return block\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
