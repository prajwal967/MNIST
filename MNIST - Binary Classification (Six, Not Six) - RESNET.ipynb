{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import residual_blocks\n",
    "#** A change was made in the residual_blocks.py file, the change is represented by #**\n",
    "#** Without the change i was getting an unbound local error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 15\n",
    "#**The program was written for CIFAR, the dimensions for the dataset are (32,32)\n",
    "#**For the MNSIT part the dataset has dimensions (28,28)\n",
    "#**The program was padding (28,28) to (32,32) and was running it\n",
    "#**The changes I made removed this padding step, and changed the dimensions  wherever necessary for running\n",
    "#**the MNIST datset\n",
    "\n",
    "#**More changes have been mentioned below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "    num_big_blocks = 3\n",
    "    image_patch_sizes = [[3,3]]*num_big_blocks\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "    n_features = [128, 256, 512, 512, 1024]\n",
    "    n_features_next = [256, 512, 512, 512, 1024]\n",
    "    #height_input = 32\n",
    "    #width_input = 32\n",
    "    #**Changed the above values to 28 for the MNIST Dataset, 32 is for CIFAR \n",
    "    #**This change means we dont have to add padding for (28,28) to (32,32) in the get_residual_model() function\n",
    "    height_input = 28\n",
    "    width_input = 28\n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(residual_blocks.building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "        #**Made pad_height and width = 0, because the above computation of them was yielding a None result\n",
    "        #**leading to an error in the program\n",
    "        #**Error was - unsupported operand types for * - int and None type\n",
    "        pad_height = 0\n",
    "        pad_width = 0\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                            n_feat_next,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                            is_subsample=True,\n",
    "                                                            subsample=pool_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=28, img_cols=28):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 128\n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((2,2), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # [END]\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_resnet():\n",
    "\n",
    "    \n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "    if is_mnist:\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        img_rows, img_cols = 28, 28\n",
    "        img_channels = 1\n",
    "        print(' == MNIST ==')\n",
    "    else:\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        img_rows, img_cols = 32, 32\n",
    "        img_channels = 3\n",
    "        print(' == CIFAR10 ==')\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    #X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    #X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "    \n",
    "    #Seed for reproducibilty\n",
    "    np.random.seed(1338)\n",
    "\n",
    "    #Selecting 6000 random examples from the test data\n",
    "    test_rows = np.random.randint(0,X_test.shape[0],6000)\n",
    "    X_test = X_test[test_rows]\n",
    "    Y = y_test[test_rows]\n",
    "    #Converting the output to binary classification(Six=1,Not Six=0)\n",
    "    Y_test = Y == 6\n",
    "    Y_test = Y_test.astype(int)\n",
    "\n",
    "    #Selecting the 5918 examples where the output is 6\n",
    "    X_six = X_train[y_train == 6]\n",
    "    Y_six = y_train[y_train == 6]\n",
    "    #Selecting the examples where the output is not 6\n",
    "    X_not_six = X_train[y_train != 6]\n",
    "    Y_not_six = y_train[y_train != 6]\n",
    "\n",
    "    #Selecting 6000 random examples from the data that contains only the data where the output is not 6\n",
    "    random_rows = np.random.randint(0,X_six.shape[0],6000)\n",
    "    X_not_six = X_not_six[random_rows]\n",
    "    Y_not_six = Y_not_six[random_rows]\n",
    "    \n",
    "    \n",
    "    #Appending the data with output as 6 and data with output as not six\n",
    "    X_train = np.append(X_six,X_not_six)\n",
    "    #Reshaping the appended data to appropraite form\n",
    "    X_train = X_train.reshape(X_six.shape[0] + X_not_six.shape[0], 1, img_rows, img_cols)\n",
    "    #Appending the labels and converting the labels to binary classification(Six=1,Not Six=0)\n",
    "    Y_labels = np.append(Y_six,Y_not_six)\n",
    "    Y_train = Y_labels == 6 \n",
    "    Y_train = Y_train.astype(int)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "    #**Changing is_mnist to false so that it runs the else statement in the function, that is there will be no \n",
    "    #** addition of padding for (28,28) to (32,32) \n",
    "    model = get_residual_model(is_mnist=False, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              verbose=1, validation_data=(X_test, Y_test))#, callbacks=[best_model])\n",
    "    score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (60000, 1, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "   - New residual block with\n",
      "      input shape: (128, 28, 28)\n",
      "      kernel size: [3, 3]\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "      input shape: (128, 28, 28)\n",
      "      kernel size: [3, 3]\n",
      "      - Input channels: 128 ---> num feature maps on out: 256\n",
      "      - with subsample: (2, 2)\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "      input shape: (256, 13, 13)\n",
      "      kernel size: [3, 3]\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "      input shape: (256, 13, 13)\n",
      "      kernel size: [3, 3]\n",
      "      - Input channels: 256 ---> num feature maps on out: 512\n",
      "      - with subsample: (2, 2)\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "      input shape: (512, 6, 6)\n",
      "      kernel size: [3, 3]\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "      input shape: (512, 6, 6)\n",
      "      kernel size: [3, 3]\n",
      "      - with subsample: (2, 2)\n",
      "        -- model was built.\n",
      "Average pooling, from (2,2) to (1,1)\n",
      "Train on 11918 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "11918/11918 [==============================] - 1599s - loss: 0.1172 - acc: 0.9640 - val_loss: 0.3572 - val_acc: 0.8845\n",
      "Epoch 2/15\n",
      "11918/11918 [==============================] - 1596s - loss: 0.0267 - acc: 0.9906 - val_loss: 0.0172 - val_acc: 0.9958\n",
      "Epoch 3/15\n",
      "11918/11918 [==============================] - 1594s - loss: 0.0138 - acc: 0.9950 - val_loss: 0.0431 - val_acc: 0.9873\n",
      "Epoch 4/15\n",
      "11918/11918 [==============================] - 1590s - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0131 - val_acc: 0.9960\n",
      "Epoch 5/15\n",
      "11918/11918 [==============================] - 1590s - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0112 - val_acc: 0.9978\n",
      "Epoch 6/15\n",
      "11918/11918 [==============================] - 1590s - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0108 - val_acc: 0.9970\n",
      "Epoch 7/15\n",
      "11918/11918 [==============================] - 1590s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0101 - val_acc: 0.9968\n",
      "Epoch 8/15\n",
      "11918/11918 [==============================] - 1595s - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0157 - val_acc: 0.9958\n",
      "Epoch 9/15\n",
      "11918/11918 [==============================] - 1599s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0275 - val_acc: 0.9930\n",
      "Epoch 10/15\n",
      "11918/11918 [==============================] - 1601s - loss: 0.0082 - acc: 0.9966 - val_loss: 0.0146 - val_acc: 0.9963\n",
      "Epoch 11/15\n",
      "11918/11918 [==============================] - 1596s - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0292 - val_acc: 0.9922\n",
      "Epoch 12/15\n",
      "11918/11918 [==============================] - 1597s - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0259 - val_acc: 0.9942\n",
      "Epoch 13/15\n",
      "11918/11918 [==============================] - 1599s - loss: 0.0286 - acc: 0.9920 - val_loss: 0.0210 - val_acc: 0.9930\n",
      "Epoch 14/15\n",
      "11918/11918 [==============================] - 1595s - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9955\n",
      "Epoch 15/15\n",
      "11918/11918 [==============================] - 1595s - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0121 - val_acc: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:429: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0121019153625\n",
      "Test accuracy: 0.996166666667\n",
      "1 loop, best of 1: 6h 42min 30s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 build_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
